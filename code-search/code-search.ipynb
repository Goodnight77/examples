{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Code search with Qdrant\n",
        "\n",
        "This is a notebook demonstrating how to implement a code search mechanism using two different neural encoders - one general purpuse, and another trained specifically for code. Let's start with installing all the required dependencies."
      ],
      "metadata": {
        "id": "FcZxcGxGRcoj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q95WbjsKW2KH"
      },
      "outputs": [],
      "source": [
        "!pip install qdrant-client inflection sentence-transformers optimum onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to work with [Qdrant source code](https://github.com/qdrant/qdrant) that has been already converted into chunks. If you want to do it for a different project, please consider using one of the [LSP implementations](https://microsoft.github.io/language-server-protocol/) for your programming language. It should be fairly easy to build similar structures with the help of these tools."
      ],
      "metadata": {
        "id": "35XOEgMTSHlk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD8Fdu1SWw_7"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/tutorial-attachments/code-search/structures.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0Fce_PAn5tG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "structures = []\n",
        "with open(\"structures.jsonl\", \"r\") as fp:\n",
        "    for i, row in enumerate(fp):\n",
        "        entry = json.loads(row)\n",
        "        structures.append(entry)\n",
        "\n",
        "structures[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use two different neural encoders - `all-MiniLM-L6-v2` and `jina-embeddings-v2-base-code`. Since the first one is trained for general purposes, and more natural language, there is a need to convert code into more human-friendly text representation. This normalization gets rid of language specifics, so the output looks more like a description of the particular code structure."
      ],
      "metadata": {
        "id": "RGpmhMjFSrHA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvg0VTwQkfnd"
      },
      "outputs": [],
      "source": [
        "import inflection\n",
        "import re\n",
        "\n",
        "from typing import Dict, Any\n",
        "\n",
        "def textify(chunk: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Convert the code structure into natural language like representation.\n",
        "\n",
        "    Args:\n",
        "        chunk (dict): Dictionary-like representation of the code structure\n",
        "            Example: {\n",
        "                \"name\":\"await_ready_for_timeout\",\n",
        "                \"signature\":\"fn await_ready_for_timeout (& self , timeout : Duration) -> bool\",\n",
        "                \"code_type\":\"Function\",\n",
        "                \"docstring\":\"= \\\" Return `true` if ready, `false` if timed out.\\\"\",\n",
        "                \"line\":44,\n",
        "                \"line_from\":43,\n",
        "                \"line_to\":51,\n",
        "                \"context\":{\n",
        "                    \"module\":\"common\",\n",
        "                    \"file_path\":\"lib/collection/src/common/is_ready.rs\",\n",
        "                    \"file_name\":\"is_ready.rs\",\n",
        "                    \"struct_name\":\"IsReady\",\n",
        "                    \"snippet\":\"    /// Return `true` if ready, `false` if timed out.\\n    pub fn await_ready_for_timeout(&self, timeout: Duration) -> bool {\\n        let mut is_ready = self.value.lock();\\n        if !*is_ready {\\n            !self.condvar.wait_for(&mut is_ready, timeout).timed_out()\\n        } else {\\n            true\\n        }\\n    }\\n\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "    Returns:\n",
        "        str: A simplified natural language like description of the structure with some context info\n",
        "            Example: \"Function Await ready for timeout that does Return true if ready false if timed out defined as Fn await ready for timeout self timeout duration bool defined in struct Isready module common file is_ready rs\"\n",
        "    \"\"\"\n",
        "    # Get rid of all the camel case / snake case\n",
        "    # - inflection.underscore changes the camel case to snake case\n",
        "    # - inflection.humanize converts the snake case to human readable form\n",
        "    name = inflection.humanize(inflection.underscore(chunk[\"name\"]))\n",
        "    signature = inflection.humanize(inflection.underscore(chunk[\"signature\"]))\n",
        "\n",
        "    # Check if docstring is provided\n",
        "    docstring = \"\"\n",
        "    if chunk[\"docstring\"]:\n",
        "        docstring = f\"that does {chunk['docstring']} \"\n",
        "\n",
        "    # Extract the location of that snippet of code\n",
        "    context = (\n",
        "        f\"module {chunk['context']['module']} \"\n",
        "        f\"file {chunk['context']['file_name']}\"\n",
        "    )\n",
        "    if chunk[\"context\"][\"struct_name\"]:\n",
        "        struct_name = inflection.humanize(\n",
        "            inflection.underscore(chunk[\"context\"][\"struct_name\"])\n",
        "        )\n",
        "        context = f\"defined in struct {struct_name} {context}\"\n",
        "\n",
        "    # Combine all the bits and pieces together\n",
        "    text_representation = (\n",
        "        f\"{chunk['code_type']} {name} \"\n",
        "        f\"{docstring}\"\n",
        "        f\"defined as {signature} \"\n",
        "        f\"{context}\"\n",
        "    )\n",
        "\n",
        "    # Remove any special characters and concatenate the tokens\n",
        "    tokens = re.split(r\"\\W\", text_representation)\n",
        "    tokens = filter(lambda x: x, tokens)\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is how the same structure looks like, after performing the normalization step:"
      ],
      "metadata": {
        "id": "CDyJEb8WTHRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textify(structures[0])"
      ],
      "metadata": {
        "id": "dpkbii8gRvJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do it for all the structures at once:"
      ],
      "metadata": {
        "id": "_CYSPs_YTMyI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tIgP_omkBYT"
      },
      "outputs": [],
      "source": [
        "text_representations = list(map(textify, structures))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created text representations might be directly used as an input to the `all-MiniLM-L6-v2` model."
      ],
      "metadata": {
        "id": "O4oN7qOjTWgq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DFkoAUSiW0Z"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "nlp_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "nlp_embeddings = nlp_model.encode(\n",
        "    text_representations, show_progress_bar=True,\n",
        ")\n",
        "nlp_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a next step, we are going to extract all the code snippets to a separate list. This will be an input to the different model we want to use."
      ],
      "metadata": {
        "id": "g_0ko4S5TbYv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y067w3WKj96o"
      },
      "outputs": [],
      "source": [
        "code_snippets = [\n",
        "    structure[\"context\"][\"snippet\"]\n",
        "    for structure in structures\n",
        "]\n",
        "code_snippets[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `jina-embeddings-v2-base-code` model is available for free, but requires accepting the rules on [the model page](https://huggingface.co/jinaai/jina-embeddings-v2-base-code). Please do it first, and put the key below."
      ],
      "metadata": {
        "id": "FuxsT6O0Tl-o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyNh8ccmlVSe"
      },
      "outputs": [],
      "source": [
        "# You have to accept the conditions in order to be able to access Jina embedding\n",
        "# model. Please visit https://huggingface.co/jinaai/jina-embeddings-v2-base-code\n",
        "# to accept the rules and generate the access token in your account settings:\n",
        "# https://huggingface.co/settings/tokens\n",
        "\n",
        "HF_TOKEN = \"THIS_IS_YOUR_TOKEN\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the token is ready, we can pass the code snippets through the second model."
      ],
      "metadata": {
        "id": "2yk2CtOtTzF8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcPlZxZmi4Ag"
      },
      "outputs": [],
      "source": [
        "code_model = SentenceTransformer(\n",
        "    \"jinaai/jina-embeddings-v2-base-code\",\n",
        "    token=HF_TOKEN,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "code_model.max_seq_length = 8192  # increase the context length window\n",
        "code_embeddings = code_model.encode(\n",
        "    code_snippets, batch_size=4, show_progress_bar=True,\n",
        ")\n",
        "code_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created embeddings have to be indexed in a Qdrant collection. For that, we need a running instance. The easiest way is to deploy it using the [Qdrant Cloud](https://cloud.qdrant.io/). There is a free tier 1GB cluster available, but you can alternatively use [a local Docker container](https://qdrant.tech/documentation/quick-start/), but running it in Google Colab might require installing Docker first."
      ],
      "metadata": {
        "id": "zCyTLRV_T5jb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw_gxsdciMgu"
      },
      "outputs": [],
      "source": [
        "QDRANT_URL = \"https://my-cluster.cloud.qdrant.io:6333\" # http://localhost:6333 for local instance\n",
        "QDRANT_API_KEY = \"THIS_IS_YOUR_API_KEY\" # None for local instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gtJ79JylztO"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "client = QdrantClient(QDRANT_URL, api_key=QDRANT_API_KEY)\n",
        "client.create_collection(\n",
        "    \"qdrant-sources\",\n",
        "    vectors_config={\n",
        "        \"text\": models.VectorParams(\n",
        "            size=nlp_embeddings.shape[1],\n",
        "            distance=models.Distance.COSINE,\n",
        "        ),\n",
        "        \"code\": models.VectorParams(\n",
        "            size=code_embeddings.shape[1],\n",
        "            distance=models.Distance.COSINE,\n",
        "        ),\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our collection should be created already. Let's finally index all the data."
      ],
      "metadata": {
        "id": "y-lz7GxsUjmt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSgNUnqnoDo1"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "points = [\n",
        "    models.PointStruct(\n",
        "        id=uuid.uuid4().hex,\n",
        "        vector={\n",
        "            \"text\": text_embedding,\n",
        "            \"code\": code_embedding,\n",
        "        },\n",
        "        payload=structure\n",
        "    )\n",
        "    for text_embedding, code_embedding, structure in zip(nlp_embeddings, code_embeddings, structures)\n",
        "]\n",
        "len(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwF-H797n-6n"
      },
      "outputs": [],
      "source": [
        "client.upload_points(\n",
        "    \"qdrant-sources\",\n",
        "    points=points,\n",
        "    batch_size=64,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to check if all the points were sent, counting them might be the easiest idea."
      ],
      "metadata": {
        "id": "c7sDJG13UoNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xifY5UVRpGSw"
      },
      "outputs": [],
      "source": [
        "client.count(\"qdrant-sources\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you, however, want to know how the count endpoint works internally in the Qdrant server, that might be a question to ask."
      ],
      "metadata": {
        "id": "_N6DDRbOUtQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How do I count points in a collection?\""
      ],
      "metadata": {
        "id": "5gig5Mx3JuSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, let's use one model at a time. Let's start with the general purpose one. We could probably omit the call to the `textify` function, but in general we should pass the input through the same process like we did for the documents."
      ],
      "metadata": {
        "id": "dqLxvfb6UzeS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOekFNy9pOMq"
      },
      "outputs": [],
      "source": [
        "hits = client.search(\n",
        "    \"qdrant-sources\",\n",
        "    query_vector=(\n",
        "        \"text\", nlp_model.encode(textify(query)).tolist()\n",
        "    ),\n",
        "    limit=5,\n",
        ")\n",
        "for hit in hits:\n",
        "    print(\n",
        "        \"| \",\n",
        "        hit.payload[\"context\"][\"module\"], \" | \",\n",
        "        hit.payload[\"context\"][\"file_name\"], \" | \",\n",
        "        hit.score, \" | `\",\n",
        "        hit.payload[\"signature\"], \"` |\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results obtained with the code specific model should be different."
      ],
      "metadata": {
        "id": "-1jqIhdhVJoS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djU_4DVQqD0s"
      },
      "outputs": [],
      "source": [
        "hits = client.search(\n",
        "    \"qdrant-sources\",\n",
        "    query_vector=(\n",
        "        \"code\", code_model.encode(query).tolist()\n",
        "    ),\n",
        "    limit=5,\n",
        ")\n",
        "for hit in hits:\n",
        "    print(\n",
        "        \"| \",\n",
        "        hit.payload[\"context\"][\"module\"], \" | \",\n",
        "        hit.payload[\"context\"][\"file_name\"], \" | \",\n",
        "        hit.score, \" | `\",\n",
        "        hit.payload[\"signature\"], \"` |\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In reality, we implemented the system with two different models, as we want to combine the results coming from both of them. We can do it with a batch request, so there is just a single call to Qdrant."
      ],
      "metadata": {
        "id": "It9JqvXDVN17"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh68mAfCsfQW"
      },
      "outputs": [],
      "source": [
        "results = client.search_batch(\n",
        "    \"qdrant-sources\",\n",
        "    requests=[\n",
        "        models.SearchRequest(\n",
        "            vector=models.NamedVector(\n",
        "                name=\"text\",\n",
        "                vector=nlp_model.encode(textify(query)).tolist()\n",
        "            ),\n",
        "            with_payload=True,\n",
        "            limit=5,\n",
        "        ),\n",
        "        models.SearchRequest(\n",
        "            vector=models.NamedVector(\n",
        "                name=\"code\",\n",
        "                vector=code_model.encode(query).tolist()\n",
        "            ),\n",
        "            with_payload=True,\n",
        "            limit=5,\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "for hits in results:\n",
        "    for hit in hits:\n",
        "        print(\n",
        "            \"| \",\n",
        "            hit.payload[\"context\"][\"module\"], \" | \",\n",
        "            hit.payload[\"context\"][\"file_name\"], \" | \",\n",
        "            hit.score, \" | `\",\n",
        "            hit.payload[\"signature\"], \"` |\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last but not least, if we want to improve the diversity of the results, grouping them by the module might be a good idea."
      ],
      "metadata": {
        "id": "x2Fmp22CVZsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = client.search_groups(\n",
        "    \"qdrant-sources\",\n",
        "    query_vector=(\n",
        "        \"code\", code_model.encode(query).tolist()\n",
        "    ),\n",
        "    group_by=\"context.module\",\n",
        "    limit=5,\n",
        "    group_size=1,\n",
        ")\n",
        "for group in results.groups:\n",
        "    for hit in group.hits:\n",
        "        print(\n",
        "            \"| \",\n",
        "            hit.payload[\"context\"][\"module\"], \" | \",\n",
        "            hit.payload[\"context\"][\"file_name\"], \" | \",\n",
        "            hit.score, \" | `\",\n",
        "            hit.payload[\"signature\"], \"` |\"\n",
        "        )"
      ],
      "metadata": {
        "id": "gmtsj0Rq0MOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a more detailed guide, please check our [code search tutorial](https://qdrant.tech/documentation/tutorials/code-search/) and [code search demo](https://github.com/qdrant/demo-code-search)."
      ],
      "metadata": {
        "id": "T1yuc8GvVniA"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}